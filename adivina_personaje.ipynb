{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb36dd56-0112-4ad0-acbb-b8107558f9dd",
   "metadata": {},
   "source": [
    "<h1 style='text-align:center'>Adivina el Personaje usando Visión por Computadora</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b827ecd3-4697-4673-9c62-e4a3ce0322aa",
   "metadata": {},
   "source": [
    "<p>Hace algún tiempo el historiador Christian Nader propuso un desafío en redes sociales que consistía en identificar la mayor cantidad de personajes históricos en una fotografía (ver portada). Pensé que sería una oportunidad para aplicar algunas técnicas de manipulación de imágenes con Python, así como también sería un buen momento para aprender a realizar búsqueda inversa de imágenes de manera programática. Esto último no es más que cargar una imagen cualquiera en un buscador de internet para averiguar de quien o de que se trata.\n",
    "\n",
    "El proceso en general es bastante simple: identificar rostros dentro de la imagen, recortarlos, guardarlos en un archivo y luego subir ese mismo archivo al buscador para saber de quien se trata. \n",
    "Para la manipulación de imágenes usaremos el paquete Open CV. Por otra parte, para las búsquedas en internet usaremos requests y beautifulSoup. También usaremos translate para traducir los resultados de las búsquedas al español. Adicionalmente, usaremos otros paquetes para la manipulación de archivos y estructuras de datos.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec1cb46-c17c-4584-aba2-45ccb505648a",
   "metadata": {},
   "source": [
    "<h2>Procedimiento</h2>\n",
    "<p>Comenzaremos con la importación de los paquetes necesarios, como detallamos al inicio. Nótese que haremos uso del comando %matplotlib inline para observar las imágenes dentro del notebook. Para el mismo propósito, en la línea siguiente especificamos las dimensiones que tendran las visualizaciones de nuestras imágenes.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1e9b2c-96f5-4d92-81b7-e00e29c0501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import requests\n",
    "from  matplotlib import pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "from translate import Translator\n",
    "import numpy as np\n",
    "import tempfile\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (12,11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04558fa1-d87f-4f0e-9989-80b02d35c34b",
   "metadata": {},
   "source": [
    "<h2>Manipulación de imágenes</h2>\n",
    "<p>Uno de los aspectos que torna sumamente práctico el desarrollo y análisis de datos con Python es la existencia de paquetes especializados, compartidos generosamente por sus creadores, que se encargan de realizar el trabajo pesado y de esa manera permitir a los usuarios entrar directamente al análisis. Este es el caso del paquete Open CV, que facilita la detección de objetos en imágenes (en nuestro caso rostros) haciendo uso de algoritmos de machine learning pre-entrenados. \n",
    "Iniciaremos por leer la imagen de los rostros de personajes históricos así como el archivo que contiene el modelo de clasificación de objetos (haar cascades). A continuación vamos a pasar la imagen a escala de grises, esto último en consideración de los requerimientos del algoritmo de clasificación.\n",
    "</p>"
    "<p>El siguiente paso es usar el clasificardor para detectar los rostros en la imagen de personajes históricos. Tal como lo señalé, los paquetes especializados tornan el análisis mucho más simple. Sin embargo, el trabajo que hacen las funciones es bastante complejo y profundo. En este caso en particular, recomiendo la leer este blog para una explicación detallada de lo que sucede tras bambalinas.\n",
    "Los parámetros que vamos a especificar son, a más de la imágen, el porcentaje de reducción de la imágen para las búsquedas consecutivas, la cantidad mínima de imágenes descartadas que limitarán la existencia de un rostro, y finalmente la dimensión del cuadrado que enmarcará los rostros (en pixeles). Con los parámetros utilizados, no se logra detectar todos los rostros, así que se pueden probar diferentes valores para obtener mejores resultados.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32536611-36c7-4452-a2cc-2c92cc6f787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath = 'personajes.jpeg'\n",
    "cascPath = 'haarcascade_frontalface_default.xml'\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "image = cv2.imread(imagePath)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = faceCascade.detectMultiScale(\n",
    "    gray,\n",
    "    scaleFactor=1.01,\n",
    "    minNeighbors=3,\n",
    "    minSize=(20, 20)\n",
    ")\n",
    "print(\"Se encontraron {0} rostros!\".format(len(faces)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afb0813-b6b9-4178-be49-25a65df4dc99",
   "metadata": {},
   "source": [
    "<p>Lo que sigue es visualizar los rostros que fueron encontrados. Dado que la variable ‘faces’ es del tipo ‘np.array’ podemos usar la vectorización en lugar de control de flujo (for loop) para procesar los rostros usando el método ‘rectangle’ del paquete cv2. Debemos especificar la ubicación de los vértices de cada cuadrado y la extensión, la escala RGB y el grosor de la línea del rectángulo.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998e6085-7dc2-41bf-81d6-be5693b12a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectangulo(a):\n",
    "    cv2.rectangle(image, (a[0], a[1]), (a[0]+ a[2], a[1] + a[3]), (0, 255, 0), 1)\n",
    "\n",
    "np.apply_along_axis(rectangulo, 1, faces)\n",
    "\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49638956-d01e-44e9-a3a8-4b9e9a2f2eae",
   "metadata": {},
   "source": [
    "<h3>Búsqueda Inversa de Imágenes</h3>\n",
    "<p>A continuación vamos recortar los rostros de la imagen, guardarlos en un archivo temporal y cargarlos en el buscador para saber de quien se trata. \n",
    "Muchos de los buscadores de internet ofrecen la posibilidad de cargar una imagen para averiguar de que se trata. A ese procedimiento se lo conoce como búsqueda inversa de imágenes.\n",
    "Por su popularidad, la primera alternativa que se viene a la mente es Google, sin embargo, varios foros especializados señalan que el buscador Yandex arroja mejores y más comprensibles resultados.\n",
    "</p>"
    "<p>En este punto es importante hacer una puntualización. Muchas páginas web, en su justo derecho, limitan las conexiones realizadas de manera programática, entre otras razones, para evitar la saturación de sus servidores. Este es el caso de Yandex, que cuando intenté buscar todas las imágenes al mismo tiempo, interpuso un requerimiento de autenticación (captcha) que debía ser completado manualmente. Por ese motivo el siguiente fragmento del código de programación se aplicará a una imagen únicamente, pese a que resultaría más conveniente insertarlo en la función ‘recorte’ para gestionarlo de manera vectorizada.\n",
    "\n",
    "Usaremos el paquete ‘requests’ para realizar una petición al servidor de Yandex, que equivale a cargar el archivo manualmente. Debemos especificar los parámetros de la búsqueda que comprendeb el servicio que requerimos (‘imagesearch’), el formato de la respuesta (‘json’) y el nombre del formulario donde subiremos la imagen (‘b-page_type_search-by-image__link’). \n",
    "Una vez que obtuvimos la respuesta, procesaremos la misma con el paquete ‘json’ y buscaremos la ‘url’ del resultado de la búsqueda.\n",
    "\n",
    "Posteriormente usaremos esa ‘url’ para solicitar a Yandex el contenido de la respuesta (que incluye el nombre del personaje histórico), valiéndonos otra vez del paquete ‘requests’.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8448dc7-1796-4bbc-a73c-c701f65dba84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recorte(a, searchUrl, params):\n",
    "    roi_color = image[a[1]: a[1] + a[3], a[0]: a[0] + a[2]]\n",
    "    try: \n",
    "        target = tempfile.NamedTemporaryFile(suffix='.jpg')\n",
    "        cv2.imwrite(target.name, roi_color)\n",
    "        files = {'upfile': ('blob', target, 'image/jpeg')}\n",
    "        response = requests.post(searchUrl, params=params, files=files)\n",
    "    finally:\n",
    "        target.close()\n",
    "    query_string = json.loads(response.content)['blocks'][0]['params']['url']\n",
    "    img_search_url= searchUrl + '?' + query_string\n",
    "    soup = BeautifulSoup(requests.get(img_search_url).text, 'lxml')\n",
    "    quien = [x.text for x in soup.find_all(name='span', attrs={'class': 'Button2-Text'})]\n",
    "    return quien\n",
    "\n",
    "faces = faces[0 , 0:] #seleccionar únicamente la primera imagen\n",
    "\n",
    "searchUrl = 'https://yandex.com/images/search'\n",
    "params = {'rpt': 'imageview', 'lang':'en','format': 'json', 'request': '{\"blocks\":[{\"block\":\"b-page_type_search-by-image__link\"}]}'}\n",
    "\n",
    "quien = np.apply_along_axis(lambda x: recorte(x, searchUrl, params), 0, faces)\n",
    "print(quien)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425187be-59bc-445f-b5f9-4221226a9de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(quien)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3370854b-01f6-4ea6-8374-72fab1307ae5",
   "metadata": {},
   "source": [
    "<p>Al revisar la respuesta, se aprecia que el resultado está escrito en Ruso, así que echaremos mano del paquete ‘translate’ para traducir los resultados (en este caso al inglés). En vista de que los resultados están albergados dentro de una lista, usaremos la función ‘map’ en lugar de control de flujo (‘for loop’) como otro ejemplo de vectorización.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456cb5dd-d57a-4ab1-8a56-3895aa622476",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator= Translator(from_lang='russian', to_lang=\"en\")\n",
    "personajes = map(translator.translate, quien)\n",
    "list(personajes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
